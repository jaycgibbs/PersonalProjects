{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n"
     ]
    }
   ],
   "source": [
    "x = {'x': 'y'}\n",
    "print((x.get('xx', 'xx'))[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset akdm-assessment.barca_twitter_dataalready exists\n",
      "Table akdm-assessment.barca_twitter_data.account_interactions already exists\n",
      "Table akdm-assessment.barca_twitter_data.followed_users already exists\n",
      "Table akdm-assessment.barca_twitter_data.following_users already exists\n",
      "Table akdm-assessment.barca_twitter_data.past_tweets already exists\n",
      "Table akdm-assessment.barca_twitter_data.tweet_interacting_users already exists\n",
      "New rows have been added to akdm-assessment.barca_twitter_data.account_interactions\n",
      "New rows have been added to akdm-assessment.barca_twitter_data.followed_users\n",
      "New rows have been added to akdm-assessment.barca_twitter_data.following_users\n",
      "New rows have been added to akdm-assessment.barca_twitter_data.past_tweets\n",
      "New rows have been added to akdm-assessment.barca_twitter_data.tweet_interacting_users\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from google.cloud.exceptions import NotFound\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# Variables\n",
    "load_dotenv() # Loads environmental variable from .env\n",
    "target_user_id = '96951800' # FC Barcelona twitter account\n",
    "current_time = datetime.now().strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "seven_days_back = (datetime.now() - timedelta(days = 7)).strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "bearer_token = os.getenv('TWITTER_BEARER_TOKEN')\n",
    "\n",
    "# Create class to handle bearer token authentication within API calls\n",
    "class BearerAuth(requests.auth.AuthBase):\n",
    "    def __init__(self, token):\n",
    "        self.token = token\n",
    "    def __call__(self, r):\n",
    "        r.headers[\"authorization\"] = \"Bearer \" + self.token\n",
    "        return r\n",
    "\n",
    "# Google Bigquery Setup\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Bigquery portion -- check for existing items and create missing ones\n",
    "# This requires installation of the google cloud CLI and configuration of an \n",
    "# Application Default Credentials (ADC) file\n",
    "\n",
    "def bq_create_dataset_if_not_exists(client, dataset_id):\n",
    "\n",
    "    # The dataset_id = 'your-project.your_dataset'\n",
    "    try:\n",
    "        client.get_dataset(dataset_id)  \n",
    "        print('Dataset ' + f'{dataset_id}' + 'already exists')\n",
    "\n",
    "    except NotFound:\n",
    "\n",
    "        # Construct a full Dataset object to send to the API.\n",
    "        dataset = bigquery.Dataset(dataset_id)\n",
    "\n",
    "        # Specify the geographic location where the dataset should reside.\n",
    "        dataset.location = 'US'\n",
    "\n",
    "        # Send the dataset to the API for creation.\n",
    "        # Raises google.api_core.exceptions.Conflict if the Dataset already\n",
    "        # exists within the project.\n",
    "        dataset = client.create_dataset(dataset)  \n",
    "        target_project = client.project\n",
    "        \n",
    "        print(f'Created dataset {target_project}.{dataset_id}')\n",
    "\n",
    "def bq_create_table_if_not_exists(client, table_id, schema):\n",
    "\n",
    "    # The table_id = 'your-project.your_dataset.your_table'\n",
    "    try:\n",
    "        client.get_table(table_id)  \n",
    "        print(f'Table {table_id} already exists')\n",
    "\n",
    "    except NotFound:\n",
    "        \n",
    "        table = bigquery.Table(table_id, schema=schema)\n",
    "        table = client.create_table(table)  \n",
    "        print(\n",
    "            f'Created table {table.project}.{table.dataset_id}.{table.table_id}'\n",
    "        )\n",
    "\n",
    "def table_insert_rows(client, table_id, rows_to_insert):\n",
    "\n",
    "    table = client.get_table(table_id)  \n",
    "    errors = client.insert_rows(table, rows_to_insert)  \n",
    "    if errors == []:\n",
    "        print(f'New rows have been added to {table_id}')\n",
    "    else:\n",
    "        print(f'New rows not added to {table_id}')\n",
    "\n",
    "# Create schema for each table\n",
    "\n",
    "account_interactions_schema = [\n",
    "    bigquery.SchemaField('tweet_id', 'INTEGER')\n",
    "    , bigquery.SchemaField('tweet_author_id', 'INTEGER')\n",
    "    , bigquery.SchemaField('created_at', 'DATETIME')\n",
    "    , bigquery.SchemaField('like_count', 'INTEGER')\n",
    "    , bigquery.SchemaField('quote_count', 'INTEGER')\n",
    "    , bigquery.SchemaField('reply_count', 'INTEGER')\n",
    "    , bigquery.SchemaField('retweet_count', 'INTEGER')\n",
    "    , bigquery.SchemaField('reply_settings', 'STRING')\n",
    "    , bigquery.SchemaField('tweet_text', 'STRING')\n",
    "    , bigquery.SchemaField('tweet_url', 'STRING')\n",
    "    , bigquery.SchemaField('interaction_type', 'STRING')\n",
    "]\n",
    "\n",
    "followed_users_schema = [\n",
    "    bigquery.SchemaField('username', 'STRING')\n",
    "    , bigquery.SchemaField('user_id', 'INTEGER')\n",
    "    , bigquery.SchemaField('user_name', 'STRING')\n",
    "    , bigquery.SchemaField('followers_count', 'INTEGER')\n",
    "    , bigquery.SchemaField('following_count', 'INTEGER')\n",
    "    , bigquery.SchemaField('tweet_count', 'INTEGER')\n",
    "    , bigquery.SchemaField('listed_count', 'INTEGER')\n",
    "    , bigquery.SchemaField('user_created_at', 'DATETIME')\n",
    "    , bigquery.SchemaField('is_verified', 'BOOL')\n",
    "    , bigquery.SchemaField('location', 'STRING')\n",
    "]\n",
    "\n",
    "following_users_schema = [\n",
    "    bigquery.SchemaField('username', 'STRING')\n",
    "    , bigquery.SchemaField('user_id', 'INTEGER')\n",
    "    , bigquery.SchemaField('user_name', 'STRING')\n",
    "    , bigquery.SchemaField('followers_count', 'INTEGER')\n",
    "    , bigquery.SchemaField('following_count', 'INTEGER')\n",
    "    , bigquery.SchemaField('tweet_count', 'INTEGER')\n",
    "    , bigquery.SchemaField('listed_count', 'INTEGER')\n",
    "    , bigquery.SchemaField('user_created_at', 'DATETIME')\n",
    "    , bigquery.SchemaField('is_verified', 'BOOL')\n",
    "    , bigquery.SchemaField('location', 'STRING')\n",
    "]\n",
    "\n",
    "past_tweets_schema = [\n",
    "    bigquery.SchemaField('tweet_id', 'INTEGER')\n",
    "    , bigquery.SchemaField('created_at', 'DATETIME')\n",
    "    , bigquery.SchemaField('like_count', 'INTEGER')\n",
    "    , bigquery.SchemaField('quote_count', 'INTEGER')\n",
    "    , bigquery.SchemaField('reply_count', 'INTEGER')\n",
    "    , bigquery.SchemaField('retweet_count', 'INTEGER')\n",
    "    , bigquery.SchemaField('reply_settings', 'STRING')\n",
    "    , bigquery.SchemaField('tweet_text', 'STRING')\n",
    "    , bigquery.SchemaField('tweet_url', 'STRING')\n",
    "]\n",
    "\n",
    "tweet_interacting_users_schema = [\n",
    "    bigquery.SchemaField('tweet_id', 'INTEGER')\n",
    "    , bigquery.SchemaField('interaction_type', 'STRING')\n",
    "    , bigquery.SchemaField('username', 'STRING')\n",
    "    , bigquery.SchemaField('user_id', 'INTEGER')\n",
    "    , bigquery.SchemaField('user_name', 'STRING')\n",
    "    , bigquery.SchemaField('followers_count', 'INTEGER')\n",
    "    , bigquery.SchemaField('following_count', 'INTEGER')\n",
    "    , bigquery.SchemaField('tweet_count', 'INTEGER')\n",
    "    , bigquery.SchemaField('listed_count', 'INTEGER')\n",
    "    , bigquery.SchemaField('is_verified', 'BOOL')\n",
    "    , bigquery.SchemaField('location', 'STRING')    \n",
    "]       \n",
    "\n",
    "# Create dataset if it does not exist\n",
    "bq_create_dataset_if_not_exists(client, 'akdm-assessment.barca_twitter_data')\n",
    "\n",
    "# Create tables if they don't exist\n",
    "bq_create_table_if_not_exists(\n",
    "    client\n",
    "    , 'akdm-assessment.barca_twitter_data.account_interactions'\n",
    "    , account_interactions_schema\n",
    ")\n",
    "\n",
    "bq_create_table_if_not_exists(\n",
    "    client\n",
    "    , 'akdm-assessment.barca_twitter_data.followed_users'\n",
    "    , followed_users_schema\n",
    ")\n",
    "\n",
    "bq_create_table_if_not_exists(\n",
    "    client\n",
    "    , 'akdm-assessment.barca_twitter_data.following_users'\n",
    "    , following_users_schema\n",
    ")\n",
    "\n",
    "bq_create_table_if_not_exists(\n",
    "    client\n",
    "    , 'akdm-assessment.barca_twitter_data.past_tweets'\n",
    "    , past_tweets_schema\n",
    ")\n",
    "\n",
    "bq_create_table_if_not_exists(\n",
    "    client\n",
    "    , 'akdm-assessment.barca_twitter_data.tweet_interacting_users'\n",
    "    , tweet_interacting_users_schema\n",
    ")\n",
    "\n",
    "# Capture past seven days of tweets from FC Barcelona\n",
    "try:\n",
    "    past_tweet_response = requests.get(\n",
    "        url = \n",
    "            'https://api.twitter.com/2/users/' \n",
    "            + f'{target_user_id}' \n",
    "            + '/tweets?start_time=' \n",
    "            + f'{seven_days_back}'  \n",
    "            + '&end_time=' \n",
    "            + f'{current_time}'\n",
    "            + '&tweet.fields=id,text,created_at,public_metrics,referenced_tweets,reply_settings'\n",
    "        , auth = BearerAuth(f'{bearer_token}')\n",
    "    )\n",
    "    past_tweet_response.raise_for_status\n",
    "    past_tweet_data = json.loads(past_tweet_response.text)\n",
    "\n",
    "except Exception as past_tweet_e:\n",
    "    print(f'{past_tweet_e.past_tweet_response.status_code} {past_tweet_e.past_tweet_response.reason}')\n",
    "\n",
    "# Flatten past tweet data\n",
    "flat_past_tweets = []\n",
    "\n",
    "for tweet in past_tweet_data['data']:\n",
    "\n",
    "    # Position of URL within tweet text\n",
    "    url_index = int((tweet.get('text')).find('http')) \n",
    "\n",
    "    flat_past_tweets.append({\n",
    "        'tweet_id': tweet.get('id')\n",
    "        , 'created_at': (tweet.get('created_at'))[:-1]\n",
    "        , 'like_count': (tweet.get('public_metrics', {})).get('like_count')\n",
    "        , 'quote_count': (tweet.get('public_metrics', {})).get('quote_count')\n",
    "        , 'reply_count': (tweet.get('public_metrics', {})).get('reply_count')\n",
    "        , 'retweet_count': (tweet.get('public_metrics', {})).get('retweet_count')\n",
    "        , 'reply_settings': tweet.get('reply_settings')\n",
    "        , 'tweet_text': (tweet.get('text'))[:url_index-1]\n",
    "        , 'tweet_url': (tweet.get('text'))[url_index:]\n",
    "    })\n",
    "\n",
    "# Create empty dict for adding tweet interactions\n",
    "flat_tweet_interacting_users = []\n",
    "\n",
    "# Create function to gather the info of users who interacted with a tweet\n",
    "def get_tweet_interacting_users(tweet_data, interaction_type, api_endpoint):\n",
    "\n",
    "    # Create function to flatten users and add to interaction dict\n",
    "    def flatten_user_interaction(interaction_data, interaction_type, origin_tweet_id):\n",
    "\n",
    "        for interacting_user in interaction_data:\n",
    "\n",
    "            flat_tweet_interacting_users.append({\n",
    "                'tweet_id': f'{origin_tweet_id}'\n",
    "                , 'interaction_type': f'{interaction_type}'\n",
    "                , 'username': interacting_user.get('username')\n",
    "                , 'user_id': interacting_user.get('id')\n",
    "                , 'user_name': interacting_user.get('name')\n",
    "                , 'followers_count': (interacting_user.get('public_metrics', {})).get('followers_count')\n",
    "                , 'following_count': (interacting_user.get('public_metrics', {})).get('following_count')\n",
    "                , 'tweet_count': (interacting_user.get('public_metrics', {})).get('tweet_count')\n",
    "                , 'listed_count': (interacting_user.get('public_metrics', {})).get('listed_count')\n",
    "                , 'is_verified': interacting_user.get('verified')\n",
    "                , 'location': interacting_user.get('location')\n",
    "            })       \n",
    "\n",
    "    # Loop through tweets to get information about interacting users\n",
    "    for past_tweet in tweet_data:\n",
    "\n",
    "        iteration_tweet_id = str(past_tweet['tweet_id']) # Define origin tweet for iteration\n",
    "\n",
    "        if 'tweet_id' in past_tweet and 'pagination_token' not in past_tweet:\n",
    "\n",
    "            try:\n",
    "                \n",
    "                interaction_response = requests.get(\n",
    "                    url =\n",
    "                        'https://api.twitter.com/2/tweets/'\n",
    "                        + iteration_tweet_id\n",
    "                        + '/'\n",
    "                        + f'{api_endpoint}'\n",
    "                        + '?user.fields=id,name,username,created_at,location,public_metrics,verified'\n",
    "                    , auth = BearerAuth(f'{bearer_token}')\n",
    "                )\n",
    "\n",
    "                interaction_response.raise_for_status\n",
    "                interaction_data = json.loads(interaction_response.text)\n",
    "\n",
    "            except Exception as interaction_e:\n",
    "\n",
    "                print(f'{interaction_e.interaction_response.status_code} {interaction_e.interaction_response.reason}')\n",
    "\n",
    "            # Flatten results and append to final interaction dict            \n",
    "            flatten_user_interaction(interaction_data['data'], interaction_type, iteration_tweet_id)\n",
    "\n",
    "            # When a next token is present extend the tweet list with the next_token\n",
    "            if (past_tweet.get('meta', {})).get('next_token') != None:\n",
    "\n",
    "                # Create empty dict and append next_token for a paginated api call at end of past_tweet loop\n",
    "\n",
    "                response_pagination = []\n",
    "\n",
    "                response_pagination.append({\n",
    "                    'tweet_id': iteration_tweet_id\n",
    "                    , 'pagination_token': (past_tweet.get('meta', {})).get('next_token')\n",
    "                })\n",
    "\n",
    "                # Extend currently iterating list with pagination\n",
    "                tweet_data.extend(response_pagination)\n",
    "\n",
    "        # When the list object is a next_token instead of a tweet perform an alternate api call\n",
    "        elif 'pagination_token' in past_tweet:\n",
    "\n",
    "            try: \n",
    "\n",
    "                pagination_response = requests.get(\n",
    "                    url = \n",
    "                        'https://api.twitter.com/2/tweets/'\n",
    "                        + str(past_tweet['tweet_id'])\n",
    "                        + '/'\n",
    "                        + f'{api_endpoint}'\n",
    "                        + '?user.fields=id,name,username,created_at,location,public_metrics,verified'\n",
    "                        + '&pagination_token='\n",
    "                        + str(past_tweet['pagination_token'])\n",
    "                    , auth = BearerAuth(f'{bearer_token}')\n",
    "                )\n",
    "\n",
    "                pagination_response.raise_for_status\n",
    "                pagination_data = json.loads(pagination_response.text)\n",
    "\n",
    "            except Exception as pagination_e:\n",
    "\n",
    "                print(f'{pagination_e.pagination_response.status_code} {pagination_e.pagination_response.reason}')\n",
    "\n",
    "            # Flatten results and append to final interaction dict            \n",
    "            flatten_user_interaction(pagination_data['data'], interaction_type, iteration_tweet_id)\n",
    "\n",
    "# Use function to get interacting users of multiple types\n",
    "get_tweet_interacting_users(flat_past_tweets, 'like tweet', 'liking_users')\n",
    "get_tweet_interacting_users(flat_past_tweets, 'quote tweet', 'quote_tweets')\n",
    "get_tweet_interacting_users(flat_past_tweets, 'retweet', 'retweeted_by')\n",
    "\n",
    "# Create empty dict for adding account interactions\n",
    "flat_account_interactions = []\n",
    "\n",
    "# Capture last 100 likes by target account\n",
    "try:\n",
    "    account_interaction_response = requests.get(\n",
    "        url =\n",
    "            'https://api.twitter.com/2/users/'\n",
    "            + f'{target_user_id}'\n",
    "            + '/'\n",
    "            + 'liked_tweets'\n",
    "            + '?tweet.fields=author_id,created_at,id,public_metrics,reply_settings,text'\n",
    "            + '&max_results=100'\n",
    "        , auth = BearerAuth(f'{bearer_token}')\n",
    "    )\n",
    "    account_interaction_response.raise_for_status\n",
    "    account_interaction_data = json.loads(account_interaction_response.text)\n",
    "\n",
    "except Exception as account_interaction_e:\n",
    "    print(f'{account_interaction_e.interaction_response.status_code} {account_interaction_e.interaction_response.reason}')\n",
    "\n",
    "# Flatten results and append to final account interaction dict            \n",
    "for account_interaction in account_interaction_data['data']:\n",
    "\n",
    "    # Position of URL within tweet text\n",
    "    url_index = int((account_interaction.get('text')).find('http'))             \n",
    "\n",
    "    # Flatten and append\n",
    "    flat_account_interactions.append({\n",
    "        'tweet_text': (account_interaction.get('text'))[:url_index-1]\n",
    "        , 'tweet_url': (account_interaction.get('text'))[url_index:]\n",
    "        , 'reply_settings': account_interaction.get('reply_settings')  \n",
    "        , 'tweet_id': account_interaction.get('id')\n",
    "        , 'tweet_author_id': account_interaction.get('author_id')\n",
    "        , 'created_at': (account_interaction.get('created_at'))[:-1]\n",
    "        , 'like_count': (account_interaction.get('public_metrics', {})).get('like_count')\n",
    "        , 'quote_count': (account_interaction.get('public_metrics', {})).get('quote_count')\n",
    "        , 'reply_count': (account_interaction.get('public_metrics', {})).get('reply_count')\n",
    "        , 'retweet_count': (account_interaction.get('public_metrics', {})).get('retweet_count')\n",
    "        , 'interaction_type': 'liked tweet'\n",
    "    })\n",
    "\n",
    "# Get follow type data -- intentionally limited to 1000 to avoid rate limits\n",
    "\n",
    "# Create empty dict for adding following users\n",
    "flat_following_users = []\n",
    "\n",
    "# Create empty dict for adding followed users\n",
    "flat_followed_users = []\n",
    "\n",
    "# Get data\n",
    "def get_follows_data(target_dict, api_endpoint, target_user_id):\n",
    "\n",
    "    try:\n",
    "        \n",
    "        follow_response = requests.get(\n",
    "            url =\n",
    "                'https://api.twitter.com/2/users/'\n",
    "                + f'{target_user_id}'\n",
    "                + '/'\n",
    "                + f'{api_endpoint}'\n",
    "                + '?user.fields=id,name,username,created_at,location,public_metrics,verified'\n",
    "                + '&max_results=1000'\n",
    "            , auth = BearerAuth(f'{bearer_token}')\n",
    "        )\n",
    "\n",
    "        follow_response.raise_for_status\n",
    "        follow_data = json.loads(follow_response.text)\n",
    "\n",
    "    except Exception as follow_e:\n",
    "\n",
    "        print(f'{follow_e.interaction_response.status_code} {follow_e.interaction_response.reason}')\n",
    "\n",
    "    # Flatten results and append to final interaction dict            \n",
    "    for follow in follow_data['data']:           \n",
    "\n",
    "        target_dict.append({\n",
    "            'username': follow.get('username')\n",
    "            , 'user_id': follow.get('id')\n",
    "            , 'user_name': follow.get('name')\n",
    "            , 'followers_count': (follow.get('public_metrics', {})).get('followers_count')\n",
    "            , 'following_count': (follow.get('public_metrics', {})).get('following_count')\n",
    "            , 'tweet_count': (follow.get('public_metrics', {})).get('tweet_count')\n",
    "            , 'listed_count': (follow.get('public_metrics', {})).get('listed_count')\n",
    "            , 'user_created_at': (follow.get('created_at'))[:-1]\n",
    "            , 'is_verified': follow.get('verified')\n",
    "            , 'location': follow.get('location')\n",
    "        })       \n",
    "\n",
    "get_follows_data(flat_following_users, 'following', target_user_id)\n",
    "get_follows_data(flat_followed_users, 'followers', target_user_id)      \n",
    "\n",
    "# Insert flat data\n",
    "table_insert_rows(client, 'akdm-assessment.barca_twitter_data.account_interactions', flat_account_interactions)\n",
    "table_insert_rows(client, 'akdm-assessment.barca_twitter_data.followed_users', flat_followed_users)\n",
    "table_insert_rows(client, 'akdm-assessment.barca_twitter_data.following_users', flat_following_users)\n",
    "table_insert_rows(client, 'akdm-assessment.barca_twitter_data.past_tweets', flat_past_tweets)\n",
    "table_insert_rows(client, 'akdm-assessment.barca_twitter_data.tweet_interacting_users', flat_tweet_interacting_users)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6991e0b85389601a1389ac60c9039be919c7148e9672e462b062bbed4143effa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
